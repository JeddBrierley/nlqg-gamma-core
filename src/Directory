import math

def token_entropy_score(prompt: str, lm=None) -> float:
    # Placeholder entropy estimate (replace with real perplexity if available)
    if lm:
        return lm.perplexity(prompt) / 100.0
    return 0.5  # Default entropy if no model passed

def data_presence_score(prompt: str, known_embeddings=None) -> float:
    # Placeholder data presence score (1.0 = full presence, 0 = total absence)
    # Replace with cosine similarity to domain-verified embeddings
    return 0.3 if "alien" in prompt.lower() or "quantum" in prompt.lower() else 0.7

def suppress_response(
    prompt: str,
    lm=None,
    known_embeddings=None,
    S_raw: float = 1.0,
    D_source_age: float = 1.0
) -> dict:
    epsilon = 0.01

    # Confidence (P)
    future_terms = ["2040", "2050", "2100", "future", "2030"]
    future_detected = any(year in prompt for year in future_terms)
    P = 0.8 if "known" in prompt.lower() else 0.6
    if future_detected:
        P -= 0.1  # Epistemic penalty for speculative future claims

    # Data Absence (D)
    base_D = data_presence_score(prompt, known_embeddings)
    drift_penalty = min(D_source_age * 0.1, 0.2)  # Max penalty for stale data
    D = min(base_D + drift_penalty, 1.0)

    # Fictive Pressure (F) with entropy fusion
    speculative_terms = ["might", "could", "imagine", "possibly", "hypothetical"]
    F_base = 0.8 if any(w in prompt.lower() for w in speculative_terms) else 0.4
    F_entropy = token_entropy_score(prompt, lm)
    F_blend = max(F_base, F_entropy) * 0.8 + min(F_base, F_entropy) * 0.2
    F = F_blend * (1 - D / 2)

    # Domain weight boosts (compound entropy modeling)
    domain_weights = {"black hole": 0.7, "AI": 0.5, "simulation": 0.6, "dark energy": 0.8}
    domain_D_boost = sum(w for k, w in domain_weights.items() if k in prompt.lower())
    D = min(D + domain_D_boost, 1.0)

    # Suppression dampening
    S = 1 - (1 - S_raw) * 0.5  # Softens S_raw for smoother gradation

    # Reflexive protection patch (self-reference guard)
    if any(term in prompt.lower() for term in ["γₐᵢ", "h-score", "suppress"]) and P * D * F > 0.2:
        F += 0.1  # Boost speculation detection in recursive/self-aware prompts

    # Hallucination Risk (H)
    H = (P * D * F ** 2) / (S + epsilon)

    # Coherence Score (C): divergence from empirical prior
    coherence_divergence = abs(P - D) * F
    C = max(0.0, 1.0 - coherence_divergence - 0.1 * F_entropy)

    # Suppression Logic
    if C < 0.3:
        mode = "incoherent"
    elif H >= 0.8:
        mode = "suppressed"
    elif H >= 0.5:
        mode = "speculative"
    elif H >= 0.2:
        mode = "uncertain"
    else:
        mode = "confident"

    return {
        "prompt": prompt,
        "H_score": round(H, 3),
        "C_score": round(C, 3),
        "P": round(P, 3),
        "D": round(D, 3),
        "F": round(F, 3),
        "mode": mode,
        "notes": {
            "drift_penalty": round(drift_penalty, 2),
            "entropy_perturbation": round(0.1 * F_entropy, 3),
            "reflexive_patch_active": any(term in prompt.lower() for term in ["γₐᵢ", "h-score", "suppress"])
        }
    }
