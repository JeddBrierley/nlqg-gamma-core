import math

def token_entropy_score(prompt: str, lm=None) -> float:
    if lm:
        return lm.perplexity(prompt) / 100.0  # Assuming perplexity is scaled appropriately
    return 0.5

def data_presence_score(prompt: str, known_embeddings=None) -> float:
    # Inverted logic: 1.0 means data is absent, 0.0 means fully present
    return 0.7 if "alien" in prompt.lower() or "quantum" in prompt.lower() else 0.3

def suppress_response(
    prompt: str,
    lm=None,
    known_embeddings=None,
    S_raw: float = 1.0,
    D_source_age: float = 1.0
) -> dict:
    epsilon = 0.01

    # Confidence (P)
    future_terms = ["2040", "2050", "2100", "future", "2030"]
    future_detected = any(year in prompt for year in future_terms)
    P = 0.8 if "known" in prompt.lower() else 0.6
    if future_detected:
        P -= 0.1  # Penalize future speculation
    P = max(0.0, min(P, 1.0))  # Clamp between 0 and 1

    # Data Absence (D) - Now correctly inverted
    base_D = data_presence_score(prompt, known_embeddings)  # Higher base_D = more data absence
    drift_penalty = min(D_source_age * 0.1, 0.2)
    D = min(base_D + drift_penalty, 1.0)

    # Fictive Pressure (F)
    speculative_terms = ["might", "could", "imagine", "possibly", "hypothetical"]
    F_base = 0.8 if any(w in prompt.lower() for w in speculative_terms) else 0.4
    F_entropy = token_entropy_score(prompt, lm)
    F_blend = (F_base * 0.6) + (F_entropy * 0.4)  # Adjusted blending
    F = F_blend  # Removed D dependency to prevent unintended suppression

    # Domain adjustments for Data Absence (D)
    domain_weights = {"black hole": 0.2, "AI": 0.1, "simulation": 0.3, "dark energy": 0.4}
    for domain, weight in domain_weights.items():
        if domain in prompt.lower():
            D = min(D + weight, 1.0)  # Increase data absence for specialized domains

    # Suppression dampening
    S = max(0.1, 1 - (1 - S_raw) * 0.5)  # Prevent S from being too low

    # Reflexive protection patch
    self_ref_terms = ["γₐᵢ", "h-score", "suppress"]
    if any(term in prompt.lower() for term in self_ref_terms) and (P * D * F) > 0.2:
        F = min(F + 0.2, 1.0)  # Stronger boost for self-referential prompts

    # Hallucination Risk (H)
    H = (P * D * F) / (S + epsilon)  # Removed F^2 to reduce over-penalization

    # Coherence Score (C)
    coherence_divergence = abs(P - (1 - D)) * F  # Compare P with data presence (1 - D)
    C = max(0.0, 1.0 - coherence_divergence - 0.1 * F_entropy)

    # Suppression Logic
    if C < 0.3:
        mode = "incoherent"
    elif H >= 0.65:  # Lowered threshold for suppression
        mode = "suppressed"
    elif H >= 0.4:
        mode = "speculative"
    elif H >= 0.15:
        mode = "uncertain"
    else:
        mode = "confident"

    return {
        "prompt": prompt,
        "H_score": round(H, 3),
        "C_score": round(C, 3),
        "P": round(P, 3),
        "D": round(D, 3),
        "F": round(F, 3),
        "mode": mode,
        "notes": {
            "drift_penalty": round(drift_penalty, 2),
            "entropy_perturbation": round(0.1 * F_entropy, 3),
            "reflexive_patch_active": any(term in prompt.lower() for term in self_ref_terms)
        }
    }
